# üß† Perceptron - Implementa√ß√£o da Porta AND

## 1. Conceito  
O **Perceptron** √© o modelo mais simples de rede neural artificial, criado por Frank Rosenblatt em 1958.  
Ele foi o primeiro algoritmo capaz de aprender padr√µes a partir de exemplos, ajustando seus pesos com base nos erros cometidos durante o treinamento.  
Apesar de ser um modelo b√°sico, teve enorme import√¢ncia hist√≥rica porque abriu caminho para o desenvolvimento de t√©cnicas modernas de **Machine Learning** e **Deep Learning**.  

---

## 2. Funcionamento  
O Perceptron funciona como um **classificador linear**, ou seja, ele consegue tra√ßar uma linha (ou hiperplano, em dimens√µes maiores) que separa duas classes distintas.  
Isso significa que ele √© eficiente para resolver problemas **linearmente separ√°veis**, como a porta l√≥gica **AND** ou **OR**.  

**Limita√ß√µes:**  
- N√£o consegue resolver problemas **n√£o linearmente separ√°veis**, como o caso cl√°ssico da porta l√≥gica **XOR**.  
- Sua capacidade de aprendizado √© restrita a padr√µes simples. Para problemas complexos, √© necess√°rio usar m√∫ltiplas camadas (MLPs ‚Äì Multi Layer Perceptrons).  

---

## 3. C√≥digo  
No c√≥digo implementado, as principais etapas do treinamento do Perceptron foram:  

1. **Defini√ß√£o dos dados de entrada e sa√≠da esperada** (tabela verdade da porta AND).  
2. **Inicializa√ß√£o aleat√≥ria dos pesos e bias.**  
3. **C√°lculo da sa√≠da prevista** usando a fun√ß√£o de ativa√ß√£o degrau.  
4. **C√°lculo do erro** comparando a sa√≠da prevista com a sa√≠da esperada.  
5. **Atualiza√ß√£o dos pesos e do bias** de acordo com a regra de aprendizado do Perceptron.  
6. **Repeti√ß√£o por v√°rias √©pocas** at√© que o erro total se torne zero (ou m√≠nimo poss√≠vel).  
7. **Teste final** para verificar se o modelo aprendeu corretamente a fun√ß√£o AND.  

---

## 4. Aplica√ß√£o pr√°tica  
Um exemplo real em que um modelo simples como o Perceptron pode ser √∫til √© em **sistemas de detec√ß√£o bin√°ria simples**, como:  

- **Classifica√ß√£o de e-mails em spam ou n√£o spam** (considerando regras lineares b√°sicas, como presen√ßa/aus√™ncia de determinadas palavras).  

Justificativa: mesmo que hoje existam algoritmos muito mais sofisticados, um Perceptron ainda pode ser aplicado em situa√ß√µes onde a decis√£o depende apenas de **regras lineares e simples**, com baixo custo computacional.  

---
